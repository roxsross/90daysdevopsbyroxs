---
title: DÃ­a 37 - CI/CD a Kubernetes con GitHub Actions y ARC (Setup Manual)
description: Implementa Actions Runner Controller sin Dev Containers para mayor control y aprendizaje
sidebar_position: 2
---

## â˜¸ï¸ CI/CD Profesional a Kubernetes - Setup Manual

![](../../static/images/banner/7.png)

> "Dominar la configuraciÃ³n manual te da el **control total** sobre tu infraestructura."

Hoy vas a aprender a:

- Configurar **Actions Runner Controller (ARC)** paso a paso manualmente
- Crear **GitHub Apps** para autenticaciÃ³n enterprise
- Implementar **escalado automÃ¡tico** de runners en K8s
- Configurar **pipelines robustos** con rollback automÃ¡tico
- Entender **cada componente** del sistema a fondo

---

## ğŸ› ï¸ Prerrequisitos

### Herramientas en tu mÃ¡quina local:
```bash
# Verificar instalaciones
docker --version
kubectl version --client
helm version
kind --version

# Si falta alguno, instalar:
# Docker: https://docs.docker.com/get-docker/
# kubectl: https://kubernetes.io/docs/tasks/tools/
# Helm: https://helm.sh/docs/intro/install/
# Kind: https://kind.sigs.k8s.io/docs/user/quick-start/
```

### Cuenta de GitHub:
- âœ… OrganizaciÃ³n o cuenta personal
- âœ… Repositorio con cÃ³digo para desplegar
- âœ… Permisos de administrador

---

## ğŸš€ Paso 1: Crear Cluster Kubernetes Local

### 1. Configurar cluster Kind con mÃºltiples nodos

`kind-config.yaml`:
```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: arc-cluster
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
- role: worker
  labels:
    tier: "runners"
- role: worker
  labels:
    tier: "apps"
```

### 2. Crear el cluster

```bash
# Eliminar cluster existente si lo hay
kind delete cluster --name arc-cluster 2>/dev/null || true

# Crear nuevo cluster
kind create cluster --config kind-config.yaml

# Verificar que estÃ© funcionando
kubectl cluster-info
kubectl get nodes -o wide
```

### 3. Configurar contexto

```bash
# Asegurar que estamos usando el contexto correcto
kubectl config use-context kind-arc-cluster
kubectl config current-context
```

---

## ğŸ” Paso 2: Crear y Configurar GitHub App

### 1. Crear GitHub App

Ve a tu GitHub: **Settings â†’ Developer settings â†’ GitHub Apps â†’ New GitHub App**

**ConfiguraciÃ³n bÃ¡sica:**
- **Name**: `ARC Runner App - [TU-NOMBRE]`
- **Homepage URL**: `https://github.com/[TU-USUARIO]`
- **Webhook**: Deshabilitado

**Repository permissions:**
- âœ… **Actions**: Read
- âœ… **Contents**: Read  
- âœ… **Metadata**: Read
- âœ… **Pull requests**: Read

**Organization permissions:**
- âœ… **Self-hosted runners**: Write

### 2. Obtener credenciales

DespuÃ©s de crear la app:

```bash
# Anotar estos valores:
echo "GitHub App ID: [APARECE_EN_LA_PÃGINA]"
echo "Installation ID: [VER_PASO_SIGUIENTE]"
```

### 3. Instalar la app en tu organizaciÃ³n

- Ir a **Install App** en la sidebar
- Seleccionar tu organizaciÃ³n/cuenta
- Elegir repositorios (All o especÃ­ficos)
- **Anotar la Installation ID** de la URL: `/settings/installations/[INSTALLATION_ID]`

### 4. Generar clave privada

- En **General â†’ Private keys**
- Click **Generate a private key**
- Descargar el archivo `.pem`

---

## âš™ï¸ Paso 3: Instalar Actions Runner Controller

### 1. Agregar repositorio Helm de ARC

```bash
# Agregar repo oficial de GitHub Actions
helm repo add actions-runner-controller \
  https://actions-runner-controller.github.io/actions-runner-controller

# Actualizar repos
helm repo update
```

### 2. Instalar el controlador principal

```bash
# Crear namespace para el sistema ARC
kubectl create namespace arc-systems

# Instalar ARC usando el nuevo chart
helm install arc \
    --namespace arc-systems \
    --create-namespace \
    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller

# Verificar instalaciÃ³n
kubectl get pods -n arc-systems
kubectl logs -n arc-systems deployment/arc-gha-rs-controller
```

---

## ğŸƒ Paso 4: Configurar Runner Scale Set

### 1. Crear archivo de configuraciÃ³n

`runner-values.yaml`:
```yaml
githubConfigUrl: "https://github.com/[TU-USUARIO-ORG]"  # ğŸ”„ CAMBIAR
githubConfigSecret: "github-app-secret"

# ConfiguraciÃ³n de escalado
minRunners: 0
maxRunners: 5

# ConfiguraciÃ³n del runner
runnerGroup: "default"
runnerScaleSetName: "roxs-k8s-runners"

# Etiquetas para el runner
template:
  spec:
    containers:
    - name: runner
      env:
      - name: RUNNER_FEATURE_FLAG_ONCE
        value: "true"
      resources:
        requests:
          cpu: "100m"
          memory: "128Mi"
        limits:
          cpu: "500m"
          memory: "512Mi"

# Node selector para runners
nodeSelector:
  tier: "runners"
```

### 2. Crear secreto con credenciales

```bash
# Crear namespace para runners
kubectl create namespace arc-runners

# Crear secreto con credenciales de GitHub App
kubectl create secret generic github-app-secret \
  --namespace=arc-runners \
  --from-literal=github_app_id="[TU_APP_ID]" \
  --from-literal=github_app_installation_id="[TU_INSTALLATION_ID]" \
  --from-file=github_app_private_key="[RUTA_A_TU_ARCHIVO].pem"

# Verificar secreto
kubectl get secret github-app-secret -n arc-runners -o yaml
```

### 3. Instalar Runner Scale Set

```bash
# Instalar usando el chart oficial
helm install roxs-k8s-runners \
    --namespace arc-runners \
    --values runner-values.yaml \
    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set

# Verificar instalaciÃ³n
kubectl get pods -n arc-runners
kubectl get runners -n arc-runners
```

### 4. Verificar en GitHub

Ve a tu repo: **Settings â†’ Actions â†’ Runners**
DeberÃ­as ver: `roxs-k8s-runners` con estado **Idle**

---

## ğŸ“¦ Paso 5: Preparar AplicaciÃ³n de Ejemplo

### 1. Crear manifiestos Kubernetes

`k8s/namespace.yaml`:
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: mi-app
  labels:
    name: mi-app
```

`k8s/deployment.yaml`:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mi-app
  namespace: mi-app
  labels:
    app: mi-app
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: mi-app
  template:
    metadata:
      labels:
        app: mi-app
      annotations:
        deployment.kubernetes.io/revision: "1"
    spec:
      nodeSelector:
        tier: "apps"
      containers:
      - name: app
        image: nginx:1.21-alpine
        ports:
        - containerPort: 80
          name: http
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        env:
        - name: BUILD_VERSION
          value: "v1.0.0"
```

`k8s/service.yaml`:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: mi-app-service
  namespace: mi-app
  labels:
    app: mi-app
spec:
  type: NodePort
  selector:
    app: mi-app
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30080
    protocol: TCP
    name: http
```

`k8s/ingress.yaml`:
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: mi-app-ingress
  namespace: mi-app
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: localhost
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: mi-app-service
            port:
              number: 80
```

---

## ğŸ”„ Paso 6: Workflows de CI/CD Avanzados

### 1. Workflow principal de despliegue

`.github/workflows/deploy-k8s.yml`:
```yaml
name: ğŸš€ Deploy a Kubernetes

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  APP_NAME: mi-app
  NAMESPACE: mi-app

jobs:
  test:
    name: ğŸ§ª Tests
    runs-on: roxs-k8s-runners
    steps:
    - name: Checkout cÃ³digo
      uses: actions/checkout@v4
      
    - name: Verificar conexiÃ³n a K8s
      run: |
        echo "ğŸ” Verificando acceso al cluster..."
        kubectl version --short
        kubectl get nodes
        
    - name: Ejecutar tests de lint
      run: |
        echo "ğŸ” Ejecutando linting..."
        # AquÃ­ van tus tests reales
        echo "âœ… Tests passed!"
        
  build:
    name: ğŸ—ï¸ Build
    needs: test
    runs-on: roxs-k8s-runners
    outputs:
      image-tag: ${{ steps.build.outputs.tag }}
    steps:
    - name: Checkout cÃ³digo
      uses: actions/checkout@v4
      
    - name: Generar tag Ãºnico
      id: build
      run: |
        TAG="v1.0.0-${GITHUB_SHA::8}"
        echo "tag=$TAG" >> $GITHUB_OUTPUT
        echo "ğŸ·ï¸ Image tag: $TAG"
        
    - name: Simular build de imagen
      run: |
        echo "ğŸ—ï¸ Building Docker image: ${{ env.APP_NAME }}:${{ steps.build.outputs.tag }}"
        # docker build -t ${{ env.APP_NAME }}:${{ steps.build.outputs.tag }} .
        # docker push ${{ env.APP_NAME }}:${{ steps.build.outputs.tag }}
        
  deploy:
    name: ğŸš€ Deploy
    needs: [test, build]
    runs-on: roxs-k8s-runners
    environment: ${{ github.event.inputs.environment || 'staging' }}
    steps:
    - name: Checkout cÃ³digo
      uses: actions/checkout@v4

    - name: Verificar cluster y contexto
      run: |
        echo "ğŸ” InformaciÃ³n del cluster:"
        kubectl config current-context
        kubectl get nodes -o wide
        kubectl get namespaces

    - name: Crear namespace si no existe
      run: |
        echo "ğŸ“¦ Preparando namespace..."
        kubectl apply -f k8s/namespace.yaml
        
    - name: Backup de configuraciÃ³n actual
      run: |
        echo "ğŸ’¾ Creando backup..."
        kubectl get deployment ${{ env.APP_NAME }} -n ${{ env.NAMESPACE }} -o yaml > backup-deployment.yaml 2>/dev/null || echo "No previous deployment found"
        
    - name: Aplicar manifiestos
      run: |
        echo "ğŸš€ Desplegando aplicaciÃ³n..."
        kubectl apply -f k8s/deployment.yaml
        kubectl apply -f k8s/service.yaml
        kubectl apply -f k8s/ingress.yaml
        
        echo "â³ Esperando que el despliegue estÃ© listo..."
        kubectl rollout status deployment/${{ env.APP_NAME }} -n ${{ env.NAMESPACE }} --timeout=300s

    - name: Verificar despliegue
      run: |
        echo "âœ… Verificando estado final:"
        kubectl get pods -n ${{ env.NAMESPACE }} -o wide
        kubectl get services -n ${{ env.NAMESPACE }}
        kubectl get ingress -n ${{ env.NAMESPACE }}
        
        echo "ğŸŒ Endpoints disponibles:"
        kubectl get endpoints -n ${{ env.NAMESPACE }}
        
    - name: Test de conectividad
      run: |
        echo "ğŸ”— Testeando conectividad..."
        kubectl run curl-test --image=curlimages/curl --rm -i --restart=Never -- \
          curl -s -o /dev/null -w "%{http_code}" http://mi-app-service.${{ env.NAMESPACE }}.svc.cluster.local || true
        
    - name: Rollback en caso de fallo
      if: failure()
      run: |
        echo "ğŸ”™ Ejecutando rollback..."
        if [ -f backup-deployment.yaml ]; then
          kubectl apply -f backup-deployment.yaml
          kubectl rollout status deployment/${{ env.APP_NAME }} -n ${{ env.NAMESPACE }}
        else
          kubectl rollout undo deployment/${{ env.APP_NAME }} -n ${{ env.NAMESPACE }}
        fi
        echo "âœ… Rollback completado"
```

### 2. Workflow para testing de escalado

`.github/workflows/test-scaling.yml`:
```yaml
name: ğŸ§ª Test Escalado de Runners

on:
  workflow_dispatch:
    inputs:
      jobs_count:
        description: 'NÃºmero de jobs paralelos'
        required: true
        default: '3'
        type: string

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
    steps:
    - id: generate
      run: |
        count=${{ github.event.inputs.jobs_count }}
        matrix=$(seq 1 $count | jq -R . | jq -s .)
        echo "matrix=$matrix" >> $GITHUB_OUTPUT

  parallel-jobs:
    needs: generate-matrix
    runs-on: roxs-k8s-runners
    strategy:
      matrix:
        job: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    steps:
    - name: Job ${{ matrix.job }}
      run: |
        echo "ğŸ‰ Job ${{ matrix.job }} ejecutÃ¡ndose en runner escalable!"
        echo "ğŸ–¥ï¸ Hostname: $(hostname)"
        echo "ğŸ“Š Recursos disponibles:"
        echo "CPU: $(nproc) cores"
        echo "RAM: $(free -h | grep Mem | awk '{print $2}')"
        echo "â° Simulando trabajo..."
        sleep 30
        echo "âœ… Job ${{ matrix.job }} completado!"

  monitor-scaling:
    runs-on: roxs-k8s-runners
    steps:
    - name: Monitorear runners
      run: |
        echo "ğŸ“Š Monitoreando escalado de runners..."
        for i in {1..10}; do
          echo "--- IteraciÃ³n $i ---"
          kubectl get pods -n arc-runners
          kubectl get runners -n arc-runners 2>/dev/null || echo "No runners CRD found"
          sleep 15
        done
```

---

## ğŸ“Š Paso 7: Monitoreo y VerificaciÃ³n

### 1. Scripts de monitoreo

`scripts/monitor-cluster.sh`:
```bash
#!/bin/bash

echo "ğŸ” Estado del Cluster Kubernetes"
echo "================================"

echo -e "\nğŸ“Š Nodos:"
kubectl get nodes -o wide

echo -e "\nğŸƒ Runners (ARC):"
kubectl get pods -n arc-systems
kubectl get pods -n arc-runners

echo -e "\nğŸ“¦ Aplicaciones:"
kubectl get pods -n mi-app -o wide

echo -e "\nğŸŒ Servicios:"
kubectl get services --all-namespaces

echo -e "\nğŸ“ˆ Uso de recursos:"
kubectl top nodes 2>/dev/null || echo "Metrics server no disponible"
kubectl top pods --all-namespaces 2>/dev/null || echo "Metrics server no disponible"

echo -e "\nğŸ“‹ Eventos recientes:"
kubectl get events --sort-by=.metadata.creationTimestamp --all-namespaces | tail -10
```

### 2. Script de diagnÃ³stico

`scripts/debug-arc.sh`:
```bash
#!/bin/bash

echo "ğŸ”§ DiagnÃ³stico de Actions Runner Controller"
echo "==========================================="

echo -e "\nğŸ“Š Estado de ARC Controller:"
kubectl get pods -n arc-systems -o wide
kubectl describe deployment arc-gha-rs-controller -n arc-systems

echo -e "\nğŸƒ Estado de Runner Scale Set:"
kubectl get pods -n arc-runners -o wide
kubectl get runners -n arc-runners 2>/dev/null || echo "No runners CRD found"

echo -e "\nğŸ“‹ Logs del Controller:"
kubectl logs -n arc-systems deployment/arc-gha-rs-controller --tail=20

echo -e "\nğŸ“‹ Logs del Listener:"
kubectl logs -n arc-runners -l app.kubernetes.io/name=gha-runner-scale-set --tail=20

echo -e "\nğŸ” Secretos:"
kubectl get secrets -n arc-runners
kubectl describe secret github-app-secret -n arc-runners

echo -e "\nâš™ï¸ ConfigMaps:"
kubectl get configmaps -n arc-runners
```

### 3. Hacer scripts ejecutables

```bash
chmod +x scripts/*.sh
```

---

## ğŸ¯ Tareas del DÃ­a

### âœ… **BÃ¡sico - ConfiguraciÃ³n:**
1. Crear cluster Kind con mÃºltiples nodos
2. Configurar GitHub App con permisos correctos  
3. Instalar ARC manualmente con Helm
4. Desplegar Runner Scale Set funcionando

### âœ… **Intermedio - CI/CD:**
5. Crear workflow completo con test/build/deploy
6. Implementar rollback automÃ¡tico
7. Probar despliegue de aplicaciÃ³n real
8. Verificar escalado con jobs paralelos

### ğŸ **Avanzado - OptimizaciÃ³n:**
9. Configurar lÃ­mites de recursos en runners
10. Implementar health checks en aplicaciÃ³n
11. Agregar monitoreo de mÃ©tricas
12. Configurar alertas por Slack/Discord

---

## ğŸ”§ Comandos Esenciales de Troubleshooting

```bash
# ğŸ” Estado general del cluster
kubectl get all --all-namespaces

# ğŸƒ Verificar runners especÃ­ficamente  
kubectl get pods -n arc-runners -w
kubectl logs -n arc-runners -l app.kubernetes.io/name=gha-runner-scale-set -f

# ğŸ“Š Monitorear eventos en tiempo real
kubectl get events --watch --all-namespaces

# ğŸ”§ Reiniciar componentes si es necesario
kubectl rollout restart deployment/arc-gha-rs-controller -n arc-systems
helm upgrade roxs-k8s-runners -n arc-runners --reuse-values \
  oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set

# ğŸ§¹ Limpiar recursos (si necesario)
kubectl delete namespace arc-runners
kubectl delete namespace arc-systems
kind delete cluster --name arc-cluster
```

---

## ğŸ§  RevisiÃ³n del DÃ­a

| Concepto | Â¿Lo dominas? | Notas |
|----------|--------------|-------|
| ConfiguraciÃ³n manual de ARC | âœ”ï¸ / âŒ | |
| GitHub Apps vs PAT tokens | âœ”ï¸ / âŒ | |
| Escalado automÃ¡tico de runners | âœ”ï¸ / âŒ | |
| Rollback automÃ¡tico en K8s | âœ”ï¸ / âŒ | |
| Debugging de pods y deployments | âœ”ï¸ / âŒ | |
| Monitoreo de recursos del cluster | âœ”ï¸ / âŒ | |

---

## ğŸ’¡ Pro Tips del DÃ­a

### ğŸš€ **Performance:**
- Usa `nodeSelector` para colocar runners y apps en nodos especÃ­ficos
- Configura `resources.requests` y `resources.limits` apropiados
- El escalado automÃ¡tico puede tardar 30-60 segundos

### ğŸ”’ **Seguridad:**
- GitHub Apps son mÃ¡s seguras que PAT tokens
- Nunca hardcodees credenciales en workflows
- Usa `secrets` de Kubernetes para datos sensibles

### ğŸ”§ **Debugging:**
- `kubectl describe` te da mÃ¡s info que `kubectl get`
- Los logs del controller ARC son clave para troubleshooting
- `kubectl get events` muestra quÃ© estÃ¡ pasando en tiempo real

### ğŸ“Š **Monitoreo:**
- Instala metrics-server para ver uso de CPU/RAM: `kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml`
- Usa `watch kubectl get pods` para monitoreo continuo
- Los runners idle consumen recursos mÃ­nimos

---

## ğŸš€ PrÃ³ximos Pasos

**DÃ­a 38 - Monitoreo y Observabilidad:**
- Prometheus + Grafana en el cluster
- Alerting inteligente con AlertManager  
- MÃ©tricas custom de aplicaciones
- Dashboards profesionales

**DÃ­a 39 - Security Hardening:**
- Network Policies para aislamiento
- Pod Security Standards
- Secrets management con External Secrets
- RBAC granular

---

## ğŸ‰ Cierre del DÃ­a

Â¡Excelente trabajo! ğŸŠ Hoy configuraste manualmente un sistema de CI/CD **enterprise-grade** sin depender de herramientas automÃ¡ticas. Esto te da:

- ğŸ¯ **Control total** sobre cada componente
- ğŸ”§ **Conocimiento profundo** para troubleshooting  
- ğŸ’ª **Habilidades transferibles** a cualquier cluster K8s
- ğŸš€ **Base sÃ³lida** para entornos de producciÃ³n

El setup manual te convierte en un **DevOps Engineer mÃ¡s completo** porque entendÃ©s cada pieza del puzzle.

ğŸ“¸ **Comparte tu cluster funcionando con #DevOpsConRoxs - DÃ­a 37**
