---
title: DÃ­a 52 - Monitorear Tu Primera AplicaciÃ³n con MÃ©tricas Custom
description: De monitorear tu sistema a monitorear TU cÃ³digo en tiempo real
sidebar_position: 3
---

## ğŸ¯ Monitorear TU AplicaciÃ³n, No Solo el Sistema

![](../../static/images/banner/8.png)

> "Ayer viste mÃ©tricas de tu computadora. Hoy vas a ver mÃ©tricas de **TU cÃ³digo ejecutÃ¡ndose** en tiempo real. Â¡Es otra cosa completamente! ğŸš€"

### ğŸ¯ **Meta del dÃ­a:**
- âœ… App simple funcionando con mÃ©tricas custom
- âœ… Ver requests, errores y tiempo de respuesta en Grafana
- âœ… "Romper" la app y ver cÃ³mo las mÃ©tricas lo detectan
- âœ… Entender: instrumentaciÃ³n de aplicaciones

---

## ğŸ¤” **Recordatorio: Â¿Por quÃ© esto es importante?**

**Ayer:** "Mi servidor estÃ¡ usando 50% CPU"
**Hoy:** "Mi endpoint `/login` tuvo 20 errores en los Ãºltimos 5 minutos"

**La diferencia es ENORME:**
- âœ… MÃ©tricas del sistema = Infraestructura
- ğŸ¯ MÃ©tricas de aplicaciÃ³n = **Tu cÃ³digo, tu lÃ³gica de negocio**

---

## ğŸ—ï¸ **Paso 1: Crear Tu Primera App Instrumentada**

Vamos a crear una API sÃºper simple pero con observabilidad profesional.

### **Estructura del proyecto:**
```
mi-app-observada/
â”œâ”€â”€ docker-compose.yml          # Stack completo
â”œâ”€â”€ prometheus.yml              # Config de Prometheus  
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt        # (Python)
â”‚   â”œâ”€â”€ package.json           # (Node.js - opcional)
â”‚   â””â”€â”€ app.py                 # Nuestra app
â””â”€â”€ grafana/
    â””â”€â”€ dashboards/
        â””â”€â”€ app-dashboard.json
```

### **OpciÃ³n 1: Python Flask** ğŸ

`app/requirements.txt`:
```txt
flask==2.3.3
prometheus-client==0.17.1
requests==2.31.0
```

`app/app.py`:
```python
from flask import Flask, jsonify, request
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
import random
import threading

app = Flask(__name__)

# ğŸ“Š MÃ‰TRICAS CUSTOM
# Counter: Solo sube (requests totales)
requests_total = Counter('app_requests_total', 'Total requests', ['method', 'endpoint', 'status'])

# Histogram: DistribuciÃ³n de tiempos
request_duration = Histogram('app_request_duration_seconds', 'Request duration', ['endpoint'])

# Gauge: Valor que sube y baja (usuarios activos)
active_users = Gauge('app_active_users', 'Currently active users')

# Counter para errores
errors_total = Counter('app_errors_total', 'Total errors', ['endpoint', 'error_type'])

# Simulamos usuarios activos que cambian
def simulate_users():
    while True:
        active_users.set(random.randint(10, 100))
        time.sleep(10)

# Iniciamos simulaciÃ³n en background
threading.Thread(target=simulate_users, daemon=True).start()

@app.route('/metrics')
def metrics():
    """Endpoint que Prometheus va a consultar"""
    return generate_latest()

@app.route('/')
def home():
    start_time = time.time()
    
    # Incrementar counter
    requests_total.labels(method='GET', endpoint='/', status='200').inc()
    
    # Simular tiempo de procesamiento
    time.sleep(random.uniform(0.1, 0.5))
    
    # Registrar duraciÃ³n
    request_duration.labels(endpoint='/').observe(time.time() - start_time)
    
    return jsonify({
        "message": "Â¡Hola! Tu app estÃ¡ siendo observada ğŸ‘€",
        "timestamp": time.time(),
        "status": "healthy"
    })

@app.route('/api/users')
def get_users():
    start_time = time.time()
    
    # Simular que a veces este endpoint falla
    if random.random() < 0.1:  # 10% de probabilidad de error
        errors_total.labels(endpoint='/api/users', error_type='database_timeout').inc()
        requests_total.labels(method='GET', endpoint='/api/users', status='500').inc()
        request_duration.labels(endpoint='/api/users').observe(time.time() - start_time)
        return jsonify({"error": "Database timeout"}), 500
    
    # Simular procesamiento
    time.sleep(random.uniform(0.2, 1.0))
    
    requests_total.labels(method='GET', endpoint='/api/users', status='200').inc()
    request_duration.labels(endpoint='/api/users').observe(time.time() - start_time)
    
    return jsonify({
        "users": [
            {"id": 1, "name": "Juan", "active": True},
            {"id": 2, "name": "MarÃ­a", "active": False},
            {"id": 3, "name": "Carlos", "active": True}
        ],
        "total": 3
    })

@app.route('/api/login', methods=['POST'])
def login():
    start_time = time.time()
    
    # Simular validaciÃ³n que a veces falla
    if random.random() < 0.15:  # 15% de logins fallan
        errors_total.labels(endpoint='/api/login', error_type='invalid_credentials').inc()
        requests_total.labels(method='POST', endpoint='/api/login', status='401').inc()
        request_duration.labels(endpoint='/api/login').observe(time.time() - start_time)
        return jsonify({"error": "Invalid credentials"}), 401
    
    time.sleep(random.uniform(0.1, 0.3))
    
    requests_total.labels(method='POST', endpoint='/api/login', status='200').inc()
    request_duration.labels(endpoint='/api/login').observe(time.time() - start_time)
    
    return jsonify({"token": "abc123", "user": "demo_user"})

@app.route('/health')
def health():
    """Health check simple"""
    requests_total.labels(method='GET', endpoint='/health', status='200').inc()
    return jsonify({"status": "UP", "timestamp": time.time()})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
```

`app/Dockerfile`:
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY app.py .

EXPOSE 5000
CMD ["python", "app.py"]
```

---

## ğŸ³ **Paso 2: Stack Completo con Docker Compose**

`docker-compose.yml`:
```yaml
version: '3.8'

services:
  # Tu aplicaciÃ³n con mÃ©tricas
  app:
    build: ./app
    container_name: mi-app
    ports:
      - "5000:5000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MÃ©tricas del sistema (del dÃ­a anterior)
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - '/:/host:ro,rslave'
    command:
      - '--path.rootfs=/host'
    restart: unless-stopped

  # Prometheus actualizado para monitorear la app
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped

  # Grafana con dashboards pre-configurados
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    restart: unless-stopped

volumes:
  grafana-storage:
```

`prometheus.yml`:
```yaml
global:
  scrape_interval: 5s  # MÃ¡s frecuente para ver cambios rÃ¡pido
  evaluation_interval: 5s

scrape_configs:
  # Sistema (como ayer)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # Prometheus se monitorea a sÃ­ mismo
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Â¡TU APP! ğŸ¯
  - job_name: 'mi-app'
    static_configs:
      - targets: ['app:5000']
    metrics_path: '/metrics'
    scrape_interval: 2s  # Muy frecuente para demos
```

---

## ğŸš€ **Paso 3: Â¡Arrancar y Probar!**

```bash
# Construir y levantar todo
docker-compose up --build -d

# Verificar que todo estÃ© corriendo
docker ps

# Verificar que la app responde
curl http://localhost:5000/
curl http://localhost:5000/api/users
curl -X POST http://localhost:5000/api/login

# Ver mÃ©tricas crudas de tu app
curl http://localhost:5000/metrics
```

**DeberÃ­as ver algo como:**
```
# HELP app_requests_total Total requests
# TYPE app_requests_total counter
app_requests_total{endpoint="/",method="GET",status="200"} 5.0
app_requests_total{endpoint="/api/users",method="GET",status="200"} 3.0
app_requests_total{endpoint="/api/users",method="GET",status="500"} 1.0

# HELP app_request_duration_seconds Request duration
# TYPE app_request_duration_seconds histogram
app_request_duration_seconds_bucket{endpoint="/",le="0.1"} 2.0
app_request_duration_seconds_bucket{endpoint="/",le="0.25"} 4.0
...
```

---

## ğŸ“Š **Paso 4: Dashboard de AplicaciÃ³n en Grafana**

### **1. Verificar Data Source:**
- Ve a Grafana: `http://localhost:3000`
- **Configuration â†’ Data Sources**
- Verificar que Prometheus estÃ© conectado

### **2. Crear Dashboard de AplicaciÃ³n:**

**Panel 1: Request Rate (RPS - Requests Per Second)**
```promql
rate(app_requests_total[1m])
```
- **Title**: "Request Rate (req/sec)"
- **Type**: Time series
- **Legend**: `{{endpoint}} - {{status}}`

**Panel 2: Error Rate**
```promql
rate(app_requests_total{status!="200"}[1m]) / rate(app_requests_total[1m]) * 100
```
- **Title**: "Error Rate (%)"
- **Type**: Time series
- **Unit**: Percent (0-100)

**Panel 3: Response Time (P95)**
```promql
histogram_quantile(0.95, rate(app_request_duration_seconds_bucket[1m]))
```
- **Title**: "Response Time P95"
- **Type**: Time series
- **Unit**: Seconds

**Panel 4: Active Users**
```promql
app_active_users
```
- **Title**: "Active Users"
- **Type**: Stat
- **Color**: Green

**Panel 5: Total Requests (por endpoint)**
```promql
increase(app_requests_total[5m])
```
- **Title**: "Requests Last 5min"
- **Type**: Bar gauge
- **Legend**: `{{endpoint}}`

**Panel 6: Errors by Type**
```promql
rate(app_errors_total[1m])
```
- **Title**: "Errors by Type"
- **Type**: Time series
- **Legend**: `{{endpoint}} - {{error_type}}`

---

## ğŸ§ª **Paso 5: Load Testing - Â¡Hacer que los GrÃ¡ficos Exploten!**

### **Script de Load Testing Simple:**

`load_test.sh`:
```bash
#!/bin/bash
echo "ğŸš€ Iniciando load test..."

# FunciÃ³n para hacer requests en paralelo
make_requests() {
    for i in {1..50}; do
        curl -s http://localhost:5000/ > /dev/null &
        curl -s http://localhost:5000/api/users > /dev/null &
        curl -s -X POST http://localhost:5000/api/login > /dev/null &
    done
    wait
}

# Ejecutar por 2 minutos
echo "ğŸ“ˆ Generando trÃ¡fico por 2 minutos..."
for round in {1..24}; do  # 24 rounds * 5 seconds = 2 minutos
    echo "Round $round/24"
    make_requests
    sleep 5
done

echo "âœ… Load test completado!"
```

```bash
chmod +x load_test.sh
./load_test.sh
```

### **O usar herramientas mÃ¡s pro:**

```bash
# Con Apache Bench (si lo tenÃ©s instalado)
ab -n 1000 -c 10 http://localhost:5000/

# Con curl en loop simple
for i in {1..100}; do
  curl -s http://localhost:5000/api/users > /dev/null &
done
```

**Â¡MirÃ¡ los dashboards mientras corren los tests!** ğŸ“Šâš¡

---

## ğŸ”¥ **Paso 6: Simular Problemas (Chaos Testing)**

### **Problema 1: App Sobrecargada**
```bash
# Stress test que genera muchos errores
for i in {1..200}; do
  curl -s http://localhost:5000/api/users > /dev/null &
  curl -s -X POST http://localhost:5000/api/login > /dev/null &
done
```

**Observar en Grafana:**
- Error rate sube
- Response time aumenta
- Request rate explota

### **Problema 2: App CaÃ­da**
```bash
# "Romper" la app
docker stop mi-app

# Esperar 1 minuto, ver mÃ©tricas en Grafana
# DespuÃ©s "arreglar":
docker start mi-app
```

**Observar en Grafana:**
- Todas las mÃ©tricas van a 0
- Gaps en los grÃ¡ficos
- Recovery cuando vuelve

### **Problema 3: Base de Datos Lenta**
```bash
# Hacer muchos requests al endpoint que simula timeouts
for i in {1..50}; do
  curl -s http://localhost:5000/api/users > /dev/null &
done
```

**Observar:**
- Error rate del endpoint `/api/users` sube
- Response time aumenta para ese endpoint especÃ­fico

---

## ğŸ¯ **Las MÃ©tricas Que Realmente Importan (SRE Level)**

### **The Golden Signals:**

1. **Latency** (Response Time)
   ```promql
   histogram_quantile(0.95, rate(app_request_duration_seconds_bucket[5m]))
   ```

2. **Traffic** (Request Rate)
   ```promql
   rate(app_requests_total[1m])
   ```

3. **Errors** (Error Rate)
   ```promql
   rate(app_requests_total{status!="200"}[1m]) / rate(app_requests_total[1m])
   ```

4. **Saturation** (Resource Usage)
   ```promql
   app_active_users / 1000  # o el lÃ­mite que tengas
   ```

### **RED Method:**
- **Rate**: Requests per second
- **Errors**: Error rate
- **Duration**: Response time

---

## ğŸ” **Paso 7: Explorar Prometheus Queries**

Ve a `http://localhost:9090` y probÃ¡ estas queries:

### **Queries Ãštiles:**
```promql
# Ver todas las mÃ©tricas de tu app
{__name__=~"app_.*"}

# Top endpoints por trÃ¡fico
topk(5, rate(app_requests_total[5m]))

# Requests que tardan mÃ¡s de 500ms
app_request_duration_seconds_bucket{le="0.5"}

# Error rate por endpoint
rate(app_requests_total{status!="200"}[5m]) by (endpoint)

# P99 response time
histogram_quantile(0.99, rate(app_request_duration_seconds_bucket[5m]) by (le, endpoint))
```

---

## ğŸ› ï¸ **Troubleshooting ComÃºn**

### **âŒ "No veo mÃ©tricas de mi app"**
```bash
# 1. Verificar que la app estÃ© expone mÃ©tricas
curl http://localhost:5000/metrics

# 2. Verificar Prometheus targets
# http://localhost:9090/targets
# Mi-app debe estar UP (verde)

# 3. Ver logs de Prometheus
docker logs prometheus
```

### **âŒ "Los grÃ¡ficos no cambian"**
- Refresh rate muy alto (ponÃ© 5s)
- Time range muy grande (ponÃ© Last 5 minutes)
- No hay trÃ¡fico en la app (hacer requests)

### **âŒ "Errors 500 en la app"**
Es normal! La app simula errores para que veas cÃ³mo se ven en las mÃ©tricas.

---

## ğŸ“š **Conceptos Clave que Aprendiste**

### **1. InstrumentaciÃ³n:**
- Agregar mÃ©tricas a TU cÃ³digo
- Counter, Gauge, Histogram
- Endpoint `/metrics` para Prometheus

### **2. Application Metrics vs System Metrics:**
- System: CPU, RAM, Disk
- Application: Requests, Errors, Business Logic

### **3. Labels y Dimensiones:**
- `endpoint`, `status`, `method`
- Permiten filtrar y agrupar
- Base de queries poderosas

### **4. Golden Signals:**
- Latency, Traffic, Errors, Saturation
- MÃ©tricas que todo SRE monitorea

---

## ğŸ§  **RevisiÃ³n del DÃ­a**

| Concepto | Â¿Lo lograste? | Notas |
|----------|---------------|-------|
| App con mÃ©tricas custom funcionando | âœ”ï¸ / âŒ | |
| Ver requests en tiempo real en Grafana | âœ”ï¸ / âŒ | |
| Generar load test y ver grÃ¡ficos cambiar | âœ”ï¸ / âŒ | |
| Simular errores y verlos en mÃ©tricas | âœ”ï¸ / âŒ | |
| Entender diferencia app vs system metrics | âœ”ï¸ / âŒ | |

---

## ğŸ¯ **Mini Challenges**

### **Challenge 1: Custom Business Metric**
AgregÃ¡ una mÃ©trica que cuente cuÃ¡ntas veces se accede a cada usuario:
```python
user_access_counter = Counter('app_user_access_total', 'User access count', ['user_id'])
```

### **Challenge 2: Performance Alert**
CreÃ¡ una query que detecte cuando el P95 response time > 1 segundo:
```promql
histogram_quantile(0.95, rate(app_request_duration_seconds_bucket[5m])) > 1
```

### **Challenge 3: Business Dashboard**
CreÃ¡ un panel que muestre mÃ©tricas de negocio:
- Logins exitosos vs fallidos
- Usuarios mÃ¡s activos
- Endpoints mÃ¡s usados

---

## ğŸ’¡ **Pro Tips del DÃ­a**

### **ğŸ¯ InstrumentaciÃ³n:**
- **No instrumentar todo** - solo lo que importa
- **Usar labels inteligentemente** - no crear demasiadas combinaciones
- **Pensar en tu audiencia** - Â¿desarrolladores o business?

### **ğŸ“Š Dashboards:**
- **Un dashboard por audiencia** (technical vs executive)
- **Colores consistentes** (rojo = malo, verde = bueno)
- **Time ranges apropiados** (5min para debugging, 24h para trends)

### **âš¡ Performance:**
- **No hacer scraping muy frecuente** en producciÃ³n (30s es normal)
- **Cuidado con labels de alta cardinalidad** (ej: user_id)
- **Usar histogramas para latency** (no averages simples)

---

## ğŸš€ **Â¿QuÃ© Sigue MaÃ±ana?**

**DÃ­a 53: Observabilidad en Kubernetes**
- Mismo concepto pero en K8s
- Prometheus Operator
- Service discovery automÃ¡tico
- Dashboards de cluster + aplicaciones

### **Para maÃ±ana mantenÃ© corriendo:**
```bash
# Este stack lo vamos a migrar a Kubernetes
docker-compose down
# Pero guardÃ¡ los archivos - los vamos a adaptar
```

---

## ğŸ‰ **Â¡IncreÃ­ble Progreso!**

Hoy diste un salto **ENORME**:

âœ… **De monitorear sistema a monitorear TU cÃ³digo**
âœ… **Instrumentaste una aplicaciÃ³n real**  
âœ… **Viste mÃ©tricas de negocio en tiempo real**
âœ… **Simulaste problemas y su detecciÃ³n**
âœ… **Aprendiste las Golden Signals (SRE nivel)**

**Lo que hiciste hoy es exactamente lo que hacen Netflix, Uber, Spotify.** 

### **Skill Level Up:** De "sÃ© usar Grafana" a **"sÃ© instrumentar aplicaciones"** ğŸ“ˆ

Eso te pone en el **top 10%** de developers que realmente entienden observabilidad.

ğŸ“¸ **CompartÃ­ tus dashboards con mÃ©tricas custom #DevOpsConRoxs - DÃ­a 52**

Â¡MaÃ±ana lo llevamos a Kubernetes! â˜¸ï¸ğŸš€